{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask-RCNN model \n",
    "\n",
    "use main Mask-RCNN model in mrcnn for traing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOTT_DIR = os.path.abspath(\"PATH/to/mrcnn\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOTT_DIR)  # To find local version of the library\n",
    "\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils\n",
    "import mrcnn.model as modellib\n",
    "import mrcnn.visualize\n",
    "from mrcnn.model import log\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           teeth\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Mask R-CNN training on the teeth dataset\n",
    "class TeethConfig(Config):\n",
    "    NAME = \"teeth\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    NUM_CLASSES = 1 + 1  # Background + tooth\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "config = TeethConfig()\n",
    "config.display()\n",
    "\n",
    "# Dataset class for loading images and masks\n",
    "class TeethDataset(mrcnn.utils.Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        super().__init__()\n",
    "\n",
    "    def load_teeth(self):\n",
    "        \n",
    "        self.add_class(\"teeth\", 1, \"tooth\") #dataset name , class id , class name\n",
    "        img_folder = os.path.join(self.dataset_path, \"images\")\n",
    "        mask_folder = os.path.join(self.dataset_path, \"masks\")\n",
    "\n",
    "        # Adding each image and its corresponding mask to the dataset\n",
    "        for img_name in os.listdir(img_folder):\n",
    "            img_id = img_name.split(\".\")[0]\n",
    "            img_path = os.path.join(img_folder, img_name)\n",
    "            mask_path = os.path.join(mask_folder, f\"{img_id}.png\")\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                self.add_image(\"teeth\", image_id=img_id, path=img_path, mask_path=mask_path)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        mask_path = info['mask_path']\n",
    "\n",
    "        # Read mask image and find contours\n",
    "        mask_image = skimage.io.imread(mask_path)\n",
    "        mask_image = skimage.color.rgb2gray(mask_image) if mask_image.ndim == 3 else mask_image\n",
    "\n",
    "        ret, thresh = cv2.threshold((mask_image * 255).astype(np.uint8), 127, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        masks = np.zeros((mask_image.shape[0], mask_image.shape[1], len(contours)), dtype=bool)\n",
    "        for i, contour in enumerate(contours):\n",
    "            contour_mask = np.zeros(mask_image.shape, dtype=np.uint8)\n",
    "            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "            masks[:, :, i] = contour_mask > 127\n",
    "\n",
    "        class_ids = np.array([1] * len(contours), dtype=np.int32)\n",
    "        return masks, class_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "downloading weights and trining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\teeth segmentation\\Main task\\Mask R-CNN\\deep-dental-image-master\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From c:\\Miniconda\\envs\\maskrcnn_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2944: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'topology'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\teeth segmentation\\Main task\\Mask R-CNN\\deep-dental-image-master\\mrcnn\\model.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[0;32m   2104\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2105\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2106\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'saving'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-79939a6fb244>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0minit_with\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"coco\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Load weights trained on MS COCO, excluding layers specific to number of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mrcnn_class_logits\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mrcnn_bbox_fc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mrcnn_bbox\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mrcnn_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0minit_with\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"last\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\teeth segmentation\\Main task\\Mask R-CNN\\deep-dental-image-master\\mrcnn\\model.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[0;32m   2106\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m             \u001b[1;31m# Keras before 2.2 used the 'topology' namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2108\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtopology\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msaving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'topology'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_train = TeethDataset(\"PATH/to/dataset\")\n",
    "dataset_train.load_teeth()\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Model Directory\n",
    "MODEL_DIR = \"PATH/to/model/directory\"\n",
    "COCO_MODEL_PATH = \"PATH/to/coco/mask_rcnn_coco.h5\" # Path to COCO trained weights\n",
    "\n",
    "#in case you don't have trained weights uncomment the following lines\n",
    "\"\"\" url = \"https://github.com/ahmedfgad/Mask-RCNN-TF2/releases/download/v3.0/mask_rcnn_coco.h5\"\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "with open(\"mask_rcnn_coco.h5\", \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=1024): \n",
    "        if chunk:\n",
    "            f.write(chunk) \"\"\"\n",
    "\n",
    "# Initialize and Load the Model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # Options: \"imagenet\", \"coco\", or \"last\"\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, excluding layers specific to number of classes\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.train(dataset_train, dataset_train,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='heads')\n",
    "\n",
    "\"\"\" # Fine-tuning\n",
    "model.train(dataset_train, dataset_validation,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=100,\n",
    "            layers=\"all\") \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
